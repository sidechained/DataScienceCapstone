Capstone: A Predictive Text App
========================================================
author: Graham Booth
date:  16/06/2022

```{r include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
```


Introducing Capstone
========================================================
- this presentation aims to describe the usage/function of our predictive text app  [Capstone](http://sidechained.shinyapps.io/DataScienceCapstone) (click to view)
- the app was created for the final project of the Data Science Specialisation (Coursera/Johns Hopkins University)
- it is based on data provided by Microsoft SwiftKey
- usage is simple/self-explanatory:
  - user types in text box
  - after a space, prediction of the next word happens 
  - predicted words appear on buttons (click to insert)

About the App
========================================================

- created using Shiny (hosted on shinyapps.io)
- can run in any standard brower
- uses a custom predictive text model/algorithm, which is:
  - pre-calculated for speed/efficiency/low memory usage
  - generated by a separate R script ("corpus_generator.r")
  - stored as a compressed .csv file ("corpus.csv.gz")
- the next slides detail how the model was developed...

About the Predictive Text Model (1)
========================================================

- model trained on English text data gathered by SwiftKey
- uses a random sample (5%) of blogs, news & tweets sets
- using the _tidytext_ library, text data is tokenised into 2 and 3 word ngrams (representing the relationship between words):
```{r eval = FALSE}
unnest_tokens(ngram_text, line, token = "ngrams", n = 2) # or n = 3
```

- each ngram is then split into:
  - a _predicted_ element (the last word of the ngram) and
  - a _predictor_ element (the preceding word/2-words)

```{r eval = FALSE}
extract(ngram_text, into = c('predictor', 'predicted'), '(.*)\\s+([^ ]+)$')
```

About the Predictive Text Model (2)
========================================================

- next we remove rows where the predicted word is profane, not english or a 'stop word' (i.e. "is", "and" etc)

```{r eval = FALSE}
filter(!predicted %in% profanity$terms) %>% 
filter(predicted %in% GradyAugmented) %>% 
filter(!predicted %in% stop_words$word) 
```

- for each predictor element, we:
  - count the number of occurrences of each predicted word
  - keep (up to) the three most frequent (our best guesses)

```{r eval = FALSE}
group_by(predictor) %>% count(predicted, sort = TRUE) %>% slice_head(n = 3) %>% select(-n)
```

About the Predictive Text Model (3)
========================================================

An extract from the text prediction model .csv file looks like this:
```{r echo = FALSE}
line1 <- read.csv("../ShinyApp/corpus.csv.gz", header = FALSE, skip = 397762, nrows = 1)
line2 <- read.csv("../ShinyApp/corpus.csv.gz", header = FALSE, skip = 400100, nrows = 1)
extract <- bind_rows(line1, line2) %>% `colnames<-`(c("predictor", "predicted1", "predicted2", "predicted3"))
knitr::kable(extract, "html")
```

- so when _on_ is entered we get _twitter_, _friday_ & _top_ as predictions
- however when _on the_ is entered we receive the more context dependent predictions _floor_, _road_ and _ground_
- if no results for _on the_ are found, the algorithm backs off to  _on_
- for app efficiency we only currently perform two-word context prediction, but this approach could be extended to longer phrases e.g. '_on the first [day] [thursday] [of]_' for more accurate

Thanks for listening - we hope you find 